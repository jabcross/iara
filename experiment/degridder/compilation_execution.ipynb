{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82091cb8",
   "metadata": {},
   "source": [
    "# Degridder Experiment - Compilation and Execution\n",
    "\n",
    "This notebook handles the compilation and execution phases of the degridder experiment.\n",
    "We're comparing with the Preesm implementation available at https://gitlab.insa-rennes.fr/Anaelle.Cloarec/degridder\n",
    "\n",
    "This notebook:\n",
    "1. Generates parametric scenarios\n",
    "2. Compiles Preesm versions\n",
    "3. Compiles IARA versions\n",
    "4. Executes both versions\n",
    "5. Collects performance data and saves it for analysis\n",
    "\n",
    "The analysis and graph generation is done in a separate notebook: `analysis.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "experiment_dir = !realpath ~/repos/iara/experiment/degridder\n",
    "experiment_dir = experiment_dir[0]\n",
    "\n",
    "grid_size = 5120\n",
    "num_visibilities = 7848960\n",
    "\n",
    "class Scenario:\n",
    "  def __init__(self, name: str, num_cores: int, num_chunks: int, num_supports: int, grid_size: int, num_visibilities: int):\n",
    "    self.name = name\n",
    "    self.instance_path = f\"{experiment_dir}/instances/{name}\"\n",
    "    self.iara_bin_path = None\n",
    "    self.preesm_bin_path = None\n",
    "    self.iara_scheduling_time = None\n",
    "    self.preesm_scheduling_time = None\n",
    "    self.srdag_edges = None\n",
    "    self.srdag_nodes = None\n",
    "    self.preesm_bin_size = None\n",
    "    self.iara_bin_size = None\n",
    "    self.num_cores = num_cores\n",
    "    self.num_supports = num_supports\n",
    "    self.num_chunks = num_chunks\n",
    "    self.num_visibilities = num_visibilities\n",
    "    self.grid_size = grid_size\n",
    "    self.dataset_size = \"large\"\n",
    "\n",
    "# Generate parametric scenarios\n",
    "\n",
    "parameters = {\n",
    "  \"NUM_CORES\" : [1,2,4,8],\n",
    "  \"NUM_CHUNK\" : [1,2,4,8,16,32,64,128,256,512],\n",
    "  \"NUM_KERNEL_SUPPORT\" : [8],\n",
    "}\n",
    "\n",
    "# parameters = {\n",
    "#   \"NUM_CORES\" : [2],\n",
    "#   \"NUM_CHUNK\" : [512],\n",
    "#   \"NUM_KERNEL_SUPPORT\" : [8],\n",
    "# }\n",
    "\n",
    "\n",
    "def shuffle(x: list):\n",
    "  # let's make sure the corner cases are checked first.\n",
    "  if len(x) <= 3:\n",
    "    return x\n",
    "  m = len(x)//2\n",
    "  return [x[0]] + [x[-1]] + [x[m]] + shuffle(x[1:m]) + shuffle(x[m+1:-1])\n",
    "\n",
    "def generate_scenario_file(num_cores: int, num_chunk: int, num_supports: int):\n",
    "    import os\n",
    "\n",
    "    scenario_name = f\"generated_large_{num_cores}cores_{num_chunk}chunks_{num_supports}supports.scenario\"\n",
    "    template_file = f\"{experiment_dir}/templates/parametric_scenario_large_{num_cores}_cores.scenario\"\n",
    "    output_path = os.path.expanduser(f\"~/repos/degridder/Scenarios/{scenario_name}\")\n",
    "\n",
    "\n",
    "    # Check if the scenario file already exists\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Scenario {scenario_name} already exists, skipping...\")\n",
    "        return scenario_name\n",
    "\n",
    "    # Check if template file exists\n",
    "    if not os.path.exists(template_file):\n",
    "        print(f\"Template file for {num_cores} cores not found: {template_file}\")\n",
    "        return None\n",
    "\n",
    "    # Read the template file\n",
    "    with open(template_file, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Replace the placeholders\n",
    "    content = content.replace('«NUM_CHUNK»', str(num_chunk))\n",
    "    content = content.replace('«NUM_KERNEL_SUPPORT»', str(num_supports))\n",
    "\n",
    "    # Write the new scenario file\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "    print(f\"Generated scenario: {scenario_name}\")\n",
    "    return scenario_name\n",
    "\n",
    "def generate_parametric_scenarios():\n",
    "  global parameters\n",
    "  global grid_size\n",
    "  global num_visibilities\n",
    "  # Let's start from the borders.\n",
    "  for name, values in parameters.items():\n",
    "    parameters[name] = shuffle(values)\n",
    "\n",
    "  print(parameters)\n",
    "\n",
    "  ! rm ~/repos/degridder/Scenarios/generated*\n",
    "\n",
    "\n",
    "  ordered_scenarios = []\n",
    "  names = list(parameters.keys())\n",
    "  for num_cores in parameters[\"NUM_CORES\"]:\n",
    "    for num_chunk in parameters[\"NUM_CHUNK\"]:\n",
    "      for num_supports in parameters[\"NUM_KERNEL_SUPPORT\"]:\n",
    "        scenario_name = generate_scenario_file(num_cores, num_chunk, num_supports)\n",
    "        scenario = Scenario(scenario_name, num_cores, num_chunk, num_supports, grid_size, num_visibilities)\n",
    "        ordered_scenarios.append(scenario)\n",
    "  return ordered_scenarios\n",
    "\n",
    "all_ordered_scenarios =  generate_parametric_scenarios()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f02231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select scenarios to run\n",
    "# ordered_scenarios = all_ordered_scenarios[10:]  # Skip first 10 scenarios\n",
    "ordered_scenarios = all_ordered_scenarios  # Run all scenarios\n",
    "\n",
    "print(f\"Running {len(ordered_scenarios)} scenarios\")\n",
    "for i, scenario in enumerate(ordered_scenarios[:5]):  # Show first 5\n",
    "    print(f\"{i+1}. {scenario.name}\")\n",
    "if len(ordered_scenarios) > 5:\n",
    "    print(f\"... and {len(ordered_scenarios) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Preesm versions, with a timeout.\n",
    "\n",
    "def compile_preesm():\n",
    "\n",
    "  %cd {experiment_dir}\n",
    "  # !rm -rf instances\n",
    "  !mkdir -p instances\n",
    "\n",
    "  for scenario_obj in ordered_scenarios:\n",
    "\n",
    "    scenario = scenario_obj.name\n",
    "\n",
    "    !mkdir -p \"{experiment_dir}/instances/{scenario}\"\n",
    "    !rm -rf \"{experiment_dir}/instances/{scenario}/*\"\n",
    "\n",
    "    command = f\"~/repos/preesm-cli/commandLinePreesm.sh ~/Downloads/preesm-3.21.0.202501251928-linux.gtk.x86_64/ ~/repos/degridder/ Codegen.workflow {scenario} >{experiment_dir}/instances/{scenario}/preesm_stdout.txt 2>{experiment_dir}/instances/{scenario}/preesm_stderr.txt\"\n",
    "\n",
    "    print(command)\n",
    "\n",
    "    ! \\time -v -o \"{experiment_dir}/instances/{scenario}/preesm_scheduling_time.txt\" timeout 3m {command}\n",
    "\n",
    "    %cd ~/repos/degridder/Code\n",
    "\n",
    "    !mkdir -p build\n",
    "    !rm -rf build/*\n",
    "    !cmake -DCMAKE_BUILD_TYPE=Release --log-level=VERBOSE -B build\n",
    "    %cd build\n",
    "    !make\n",
    "\n",
    "    ! rm -rf \"{experiment_dir}/instances/{scenario}/preesm_build\"\n",
    "    ! cp -r ~/repos/degridder/Code/build \"{experiment_dir}/instances/{scenario}/preesm_build\"\n",
    "\n",
    "compile_preesm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9957937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry compilation for scenarios where Preesm failed with increased timeout\n",
    "for scenario_obj in ordered_scenarios:\n",
    "  scenario = scenario_obj.name\n",
    "  preesm_bin_path = f\"{experiment_dir}/instances/{scenario}/preesm_build/degridder_pipeline\"\n",
    "  if not os.path.exists(preesm_bin_path):\n",
    "    print(f\"Retrying compilation for scenario: {scenario} with 5m timeout\")\n",
    "    !mkdir -p \"{experiment_dir}/instances/{scenario}\"\n",
    "    !rm -rf \"{experiment_dir}/instances/{scenario}/*\"\n",
    "\n",
    "    command = f\"~/repos/preesm-cli/commandLinePreesm.sh ~/Downloads/preesm-3.21.0.202501251928-linux.gtk.x86_64/ ~/repos/degridder/ Codegen.workflow {scenario} >{experiment_dir}/instances/{scenario}/preesm_stdout.txt 2>{experiment_dir}/instances/{scenario}/preesm_stderr.txt\"\n",
    "    ! \\time -v -o \"{experiment_dir}/instances/{scenario}/preesm_scheduling_time.txt\" timeout 5m {command}\n",
    "\n",
    "    %cd ~/repos/degridder/Code\n",
    "    !mkdir -p build\n",
    "    !rm -rf build/*\n",
    "    !cmake -DCMAKE_BUILD_TYPE=Release --log-level=VERBOSE -B build\n",
    "    %cd build\n",
    "    !make\n",
    "\n",
    "    ! rm -rf \"{experiment_dir}/instances/{scenario}/preesm_build\"\n",
    "    ! cp -r ~/repos/degridder/Code/build \"{experiment_dir}/instances/{scenario}/preesm_build\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6906bee6",
   "metadata": {},
   "source": [
    "Now, let's compile our IARA version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {experiment_dir}\n",
    "\n",
    "for scenario in ordered_scenarios:\n",
    "  scenario.topology_file = f\"{experiment_dir}/instances/{scenario.name}/build/topology.mlir\"\n",
    "  scenario.main_file = f\"{experiment_dir}/instances/{scenario.name}/build/main.cpp\"\n",
    "  scenario.iara_build_dir = f\"{experiment_dir}/instances/{scenario.name}/build\"\n",
    "  ! mkdir -p {scenario.iara_build_dir}\n",
    "  ! rm -rf {scenario.iara_build_dir}/*\n",
    "  %cd {scenario.iara_build_dir}\n",
    "  assert os.getcwd() == scenario.iara_build_dir, f\"Not in expected build dir: {os.getcwd()} vs {scenario.iara_build_dir}\"\n",
    "  ! SCHEDULER_MODE=virtual-fifo sh -x ../../../build_instance.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb46987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute both versions for performance measurement\n",
    "\n",
    "for scenario in ordered_scenarios:\n",
    "  %cd {scenario.instance_path}/build\n",
    "  ! NUM_CORES={scenario.num_cores} sh -x ../../../run_instance.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect compilation data from Preesm\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "for scenario in all_ordered_scenarios:\n",
    "  scenario.preesm_bin_path = f'{experiment_dir}/instances/{scenario.name}/preesm_build/degridder_pipeline'\n",
    "  if os.path.exists(scenario.preesm_bin_path):\n",
    "    scenario.preesm_bin_size = os.path.getsize(scenario.preesm_bin_path)\n",
    "    walltime_str = ! grep \"wall clock\" '{experiment_dir}/instances/{scenario.name}/preesm_scheduling_time.txt' | cut -f 8 -d ' '\n",
    "    time_str = walltime_str[0].strip()\n",
    "    minutes, seconds = time_str.split(':')\n",
    "    scenario.preesm_scheduling_time = float(minutes) * 60 + float(seconds)\n",
    "\n",
    "  srdag_output = ! grep \"SRDAG\" {experiment_dir}/instances/{scenario.name}/preesm_stdout.txt\n",
    "  if srdag_output and len(srdag_output) > 0:\n",
    "    match = re.search(r'SRDAG with (\\d+) vertices and (\\d+) edges', srdag_output[0])\n",
    "    if match:\n",
    "      scenario.srdag_nodes = int(match.group(1))\n",
    "      scenario.srdag_edges = int(match.group(2))\n",
    "    else:\n",
    "      scenario.srdag_nodes = None\n",
    "      scenario.srdag_edges = None\n",
    "\n",
    "!ls -lah {experiment_dir}/instances/*/preesm_build/degridder_pipeline\n",
    "\n",
    "print(\"Preesm compilation results:\")\n",
    "for s in ordered_scenarios:\n",
    "    status = \"✓\" if s.preesm_bin_size else \"✗\"\n",
    "    size = f\"{s.preesm_bin_size/1024:.1f}KB\" if s.preesm_bin_size else \"N/A\"\n",
    "    edges = str(s.srdag_edges) if s.srdag_edges else \"N/A\"\n",
    "    print(f\"{status} {s.name[:30]:<30} | Size: {size:<8} | Edges: {edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d64568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect compilation data from IARA\n",
    "\n",
    "for scenario in all_ordered_scenarios:\n",
    "  scenario.iara_bin_path = f'{experiment_dir}/instances/{scenario.name}/build/degridder_pipeline'\n",
    "  if os.path.exists(scenario.iara_bin_path):\n",
    "    scenario.iara_bin_size = os.path.getsize(scenario.iara_bin_path)\n",
    "    walltime_str = ! grep \"wall clock\" '{experiment_dir}/instances/{scenario.name}/iara_scheduling_time.txt' | cut -f 8 -d ' '\n",
    "    time_str = walltime_str[0].strip()\n",
    "    minutes, seconds = time_str.split(':')\n",
    "    scenario.iara_scheduling_time = float(minutes) * 60 + float(seconds)\n",
    "\n",
    "!ls -lah {experiment_dir}/instances/*/build/degridder_pipeline\n",
    "\n",
    "print(\"IARA compilation results:\")\n",
    "for s in ordered_scenarios:\n",
    "    status = \"✓\" if s.iara_bin_size else \"✗\"\n",
    "    size = f\"{s.iara_bin_size/1024:.1f}KB\" if s.iara_bin_size else \"N/A\"\n",
    "    sched_time = f\"{s.iara_scheduling_time:.2f}s\" if s.iara_scheduling_time else \"N/A\"\n",
    "    print(f\"{status} {s.name[:30]:<30} | Size: {size:<8} | Scheduling: {sched_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c0c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment completion summary\n",
    "print(\"\n",
    "=== EXPERIMENT COMPLETE ===\")\n",
    "print(f\"Total scenarios processed: {len(all_ordered_scenarios)}\")\n",
    "print(f\"Scenarios with Preesm results: {sum(1 for s in all_ordered_scenarios if s.preesm_bin_size)}\")\n",
    "print(f\"Scenarios with IARA results: {sum(1 for s in all_ordered_scenarios if s.iara_bin_size)}\")\n",
    "\n",
    "# Count execution data by checking if files exist\n",
    "preesm_exec_count = 0\n",
    "iara_exec_count = 0\n",
    "for scenario in all_ordered_scenarios:\n",
    "    preesm_time_file = f'{experiment_dir}/instances/{scenario.name}/preesm_degridder_time.txt'\n",
    "    iara_time_file = f'{experiment_dir}/instances/{scenario.name}/iara_degridder_time.txt'\n",
    "    if os.path.exists(preesm_time_file):\n",
    "        preesm_exec_count += 1\n",
    "    if os.path.exists(iara_time_file):\n",
    "        iara_exec_count += 1\n",
    "\n",
    "print(f\"Execution data files - Preesm: {preesm_exec_count}, IARA: {iara_exec_count}\")\n",
    "print(f\"\n",
    "Experiment data is stored in: {experiment_dir}/instances/\")\n",
    "print(\"Ready for analysis! Run the analysis.ipynb notebook to generate graphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect execution performance data\n",
    "\n",
    "def parse_time_file(file_path):\n",
    "    \"\"\"Parse /usr/bin/time -v output to extract wall time and max RSS\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract wall clock time (format: h:mm:ss or mm:ss.ss)\n",
    "        wall_time_match = re.search(r'Elapsed \\(wall clock\\) time \\(h:mm:ss or m:ss\\): (.+)', content)\n",
    "        wall_time_seconds = None\n",
    "        if wall_time_match:\n",
    "            time_str = wall_time_match.group(1).strip()\n",
    "            if ':' in time_str:\n",
    "                parts = time_str.split(':')\n",
    "                if len(parts) == 3:  # h:mm:ss\n",
    "                    hours, minutes, seconds = parts\n",
    "                    wall_time_seconds = float(hours) * 3600 + float(minutes) * 60 + float(seconds)\n",
    "                elif len(parts) == 2:  # mm:ss\n",
    "                    minutes, seconds = parts\n",
    "                    wall_time_seconds = float(minutes) * 60 + float(seconds)\n",
    "            else:\n",
    "                wall_time_seconds = float(time_str)\n",
    "        \n",
    "        # Extract maximum resident set size (in KB)\n",
    "        max_rss_match = re.search(r'Maximum resident set size \\(kbytes\\): (\\d+)', content)\n",
    "        max_rss_kb = int(max_rss_match.group(1)) if max_rss_match else None\n",
    "        \n",
    "        return wall_time_seconds, max_rss_kb\n",
    "    except FileNotFoundError:\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Extract execution data for all scenarios\n",
    "for scenario in all_ordered_scenarios:\n",
    "    # Parse Preesm execution data\n",
    "    preesm_time_file = f'{experiment_dir}/instances/{scenario.name}/preesm_degridder_time.txt'\n",
    "    scenario.preesm_wall_time, scenario.preesm_max_rss = parse_time_file(preesm_time_file)\n",
    "    \n",
    "    # Parse IARA execution data\n",
    "    iara_time_file = f'{experiment_dir}/instances/{scenario.name}/iara_degridder_time.txt'\n",
    "    scenario.iara_wall_time, scenario.iara_max_rss = parse_time_file(iara_time_file)\n",
    "\n",
    "print(\"Execution Performance Summary:\")\n",
    "print(\"Scenario | Preesm Wall Time (s) | IARA Wall Time (s) | Preesm Max RSS (KB) | IARA Max RSS (KB)\")\n",
    "print(\"-\" * 90)\n",
    "for scenario in ordered_scenarios:\n",
    "    preesm_wt = f\"{scenario.preesm_wall_time:.2f}\" if scenario.preesm_wall_time else \"N/A\"\n",
    "    iara_wt = f\"{scenario.iara_wall_time:.2f}\" if scenario.iara_wall_time else \"N/A\"\n",
    "    preesm_rss = str(scenario.preesm_max_rss) if scenario.preesm_max_rss else \"N/A\"\n",
    "    iara_rss = str(scenario.iara_max_rss) if scenario.iara_max_rss else \"N/A\"\n",
    "    print(f\"{scenario.name[:20]:<20} | {preesm_wt:>17} | {iara_wt:>15} | {preesm_rss:>16} | {iara_rss:>14}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment completion summary\n",
    "print(\"\\n=== EXPERIMENT COMPLETE ===\")\n",
    "print(f\"Total scenarios processed: {len(all_ordered_scenarios)}\")\n",
    "print(f\"Scenarios with Preesm results: {sum(1 for s in all_ordered_scenarios if s.preesm_bin_size)}\")\n",
    "print(f\"Scenarios with IARA results: {sum(1 for s in all_ordered_scenarios if s.iara_bin_size)}\")\n",
    "\n",
    "# Count execution data by checking if files exist\n",
    "preesm_exec_count = 0\n",
    "iara_exec_count = 0\n",
    "for scenario in all_ordered_scenarios:\n",
    "    preesm_time_file = f'{experiment_dir}/instances/{scenario.name}/preesm_degridder_time.txt'\n",
    "    iara_time_file = f'{experiment_dir}/instances/{scenario.name}/iara_degridder_time.txt'\n",
    "    if os.path.exists(preesm_time_file):\n",
    "        preesm_exec_count += 1\n",
    "    if os.path.exists(iara_time_file):\n",
    "        iara_exec_count += 1\n",
    "\n",
    "print(f\"Execution data files - Preesm: {preesm_exec_count}, IARA: {iara_exec_count}\")\n",
    "print(f\"\\nExperiment data is stored in: {experiment_dir}/instances/\")\n",
    "print(\"Ready for analysis! Run the analysis.ipynb notebook to generate graphs.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
